[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Principes, procédures et tips pour traiter les données dans R",
    "section": "",
    "text": "Préface\nPourquoi ce livre ? Contexte."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Comment lire ce livre",
    "section": "",
    "text": "philosophie, utilisation"
  },
  {
    "objectID": "01_environnement.html#github-et-structure-des-dossiers",
    "href": "01_environnement.html#github-et-structure-des-dossiers",
    "title": "1  Environnement de travail",
    "section": "1.1 GitHub et structure des dossiers",
    "text": "1.1 GitHub et structure des dossiers\n\nOn dispose d’un compte chez GitHub. Le compte est lié à 3 machines (2 macs et un pc). Le commit et le push se réalisent depuis RStudio directement. Sur chaque machine, on s’offre tout de même une solution user friendly avec GitHub Desktop.\nSur chaque machine, on dispose d’une structure des dossiers de type Documents > GitHub > r-projects (attention à la casse).\nLe dossier r-projects contient autant de sous-dossiers que de projets à analyser.\nChaque sous-dossier a un nom structuré ainsi (attention à la casse) : contexteannée_initialesauteurprincipal (par exemple : dupp2019_cr ou crips2019_lv).\nDans chaque sous-dossier:\n\nun fichier Rproj est disponible et il porte le nom du sous-dossier\nun fichier présentant les données brutes (raw) est disponible (en lecture seule de préférence) et il porte un titre de la forme nomsousdossier_raw. Il peut être en format .csv ou .xlsx. Si les données brutes sont sur plusieurs fichiers (dans le cas de plusieurs temps de mesure, par exemple, on les distingue avec l’ajout *_t1*, …)\nun fichier de script .R intitulé nomsousdossier_script\nun fichier Rmarkdown .Rmd intitulé nomsousdossier_rapport et rédigé en parallèle du script. Ce rapport général appelle le script pour réaliser les sorties.\n\n\nOn ne s’est pas encore déterminé sur les bonnes pratiques pour la constitution du rapport en RMarkdown : Est-ce OK et satisfaisant de “simplement” rappeler le script et uniquement “afficher” les objets ?\n\n\nles sorties de type HTML, PDF, ou image (png, svg, …) n’obéissent pas à des règles précises.\nplusieurs rapports peuvent coexister en fonction des destinataires ; ils sont tous une adaptation du rapport “master” décrit plus haut.\n\nL’intérêt est d’avoir à tout moment sur GitHub une vision claire des modifications réalisées à travers les différentes étapes de mise à jour des fichier (traçabilité de la démarche). De plus, une attention particulière est accordée à l’écriture d’un code avec une grammaire (le plus possible) conventionnelle qui est lisible et commenté, que ce soit dans le script ou dans le rapport en RMarkdown.\nLe script et le rapport se rédigent en parallèle."
  },
  {
    "objectID": "01_environnement.html#rédaction-du-code-et-grammaire",
    "href": "01_environnement.html#rédaction-du-code-et-grammaire",
    "title": "1  Environnement de travail",
    "section": "1.2 Rédaction du code et grammaire",
    "text": "1.2 Rédaction du code et grammaire\nLe code suivant est, à notre sens, un exemple de bonne pratique car :\n\ndes titres mis en évidence structurent le code\nles commentaires sont présents; ils se veulent précis et concis\ndes espaces facilitent la lecture\nle code n’est pas - à notre connaissance - inutilement répétitif\n\n\n###############\n#visualisation#\n###############\n\n#score échelle HBSC\n\nvis_hbs <- d_long_paired %>% \n  ggplot() +\n  aes(x = temps, color = group, y = hbs_sco) +\n  geom_boxplot(alpha = .5) +\n  geom_jitter(size = 5, alpha = .5, position = position_jitterdodge(dodge.width=.7, jitter.width = .2)) +\n  stat_summary(fun = mean, geom = \"point\", size = 3, shape = 4) +\n  stat_summary(fun = mean, aes(group = group), geom = \"line\") +\n  labs(title = \"Mesure des CPS\", y = \"Score au HBSC\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  scale_color_brewer(\"Groupe\", palette = \"Set1\")\n\nUn autre exemple illustre cette grammaire. On rajoute quelques espaces pour faciliter la lecture et repérer les structures - parfois nécessairement - répétitives :\n\nOn aimerait toutefois savoir comment éviter ces répétitions. Notamment quand on génère 10 graphiques qui ne varient, dans le code, qu’au niveau de l’axe Y et le titre, par exemple.\n\n\n#Création des moyennes de chaque questionnaire pour chaque observation\n\nd_long <- d_long %>% \n  mutate(hbs_sco = rowMeans(select(.,starts_with(\"hbs\")),na.rm =T),\n         pec_sco = rowMeans(select(.,starts_with(\"pec\")),na.rm =T),\n         be_sco  = rowMeans(select(.,starts_with(\"be\")) ,na.rm =T),\n         est_sco = rowMeans(select(.,starts_with(\"est\")),na.rm =T),\n         cli_sco = rowMeans(select(.,starts_with(\"cli\")),na.rm =T),\n         sou_sco = rowMeans(select(.,starts_with(\"sou\")),na.rm =T),\n         mot_sco = rowMeans(select(.,starts_with(\"hbs\")),na.rm =T))\n\nUne source pour la grammaire du codage peut être consultée à l’adresse : https://www.inwt-statistics.com/read-blog/inwts-guidelines-for-r-code.html"
  },
  {
    "objectID": "01_environnement.html#rstudio-et-packages",
    "href": "01_environnement.html#rstudio-et-packages",
    "title": "1  Environnement de travail",
    "section": "1.3 RStudio et packages",
    "text": "1.3 RStudio et packages\nOn dispose en l’état de la version 4.0.2 de R ainsi que de la version 1.3.959 de RStudio.\nSur les macs, différents ajouts comme Xquartz ou des modules liés à LaTeX sont également installés.\n\nMais honnêtement, on a perdu de vue leur rôle plus ou moins nécessaire sachant que LaTeX est certes nécessaire pour les sorties PDF sans que toutes les extensions liées à LaTex le soient… Ce sera à clarifier au prochain clean install.\n\nPour la version PC, on a installé tinyTEX ‘tinytex::install_tinytex()’ directement ‘TinyTeX to C:/Users/nbr/AppData/Roaming/TinyTeX’ depuis la console. On rappelle que LaTeX est nécessaire à la génération de PDF.\nDans R, les packages suivants sont installés:\n\ntidyverse, suite de packages pour travailler de manière tidy (bien rangé) : ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, forcats.\nreadxl, permet de lire et importer les fichiers .xlsx.\nbookdown, permet de réaliser à peu de frais le présent livre\n\nEn principe, pour des raisons d’élégance du code, on cherche à limiter la sur-installation de nouveaux packages. Il s’agit d’explorer ce que les packages installés ont à offrir avant de courir sur d’autres fonctions vues sur le web."
  },
  {
    "objectID": "01_environnement.html#sublime-text-et-packages",
    "href": "01_environnement.html#sublime-text-et-packages",
    "title": "1  Environnement de travail",
    "section": "1.4 Sublime Text et Packages",
    "text": "1.4 Sublime Text et Packages\nL’utilisation de Sublime Tex est ergonomique. Les packages du logiciel permettent de travailler comme R Studio, avec toutefois un environnement plus aéré et propice à la rédaction avec des codes couleurs agréables. Il est complémentaire à RStudio mais peut carrément le remplacer pour certaines courtes étapes de rédaction.\nLes packages installés sont:\n\nsur PC : R-Box, R-IDE, LSP\nsur MAC : R-Box, SendCode\n\n\nOn doit encore clarifier comment lier sur PC et MAC GitHub. Mais ce n’est pas prioritaire. GitHub sur Sublime Text ? Emmet, git, sublime github. https://gist.github.com/KedrikG/f7b955dc371b1204ec76ce862e2dcd2e"
  },
  {
    "objectID": "01_environnement.html#scrivener-3-zotero-betterbibtext---rédaction-darticles-longs",
    "href": "01_environnement.html#scrivener-3-zotero-betterbibtext---rédaction-darticles-longs",
    "title": "1  Environnement de travail",
    "section": "1.5 Scrivener 3 + Zotero + BetterBibText - Rédaction d’articles longs",
    "text": "1.5 Scrivener 3 + Zotero + BetterBibText - Rédaction d’articles longs\nOn doit déterminer comment travailler en RMarkdown pour des articles longs via Scrivener 3. Ce logiciel a l’avantage de facilement découper l’article en plusieurs zones de travail et fusionner le tout à l’export. De plus, on peut lier dynamiquement la rédaction à Zotero via un fichier Bibtex ce qui est très intéressant.\nOn pense aussi à rassembler les éléments rédigés dans Scrivener et compiler le tout avec Bookdown sous R.\nUn hypothétique *workflow” serait : script dans R > ébauche de rapport dans R (RMarkdown) > copier/coller de l’ébauche de rapport dans Scrivener > rédaction dans Scrivener en compatibilité avec Bookdown > export de Scrivener dans R > préparation de la sortie avec Bookdown.\nMais ce n’est pas optimal. Notre souhait est de pouvoir, p.ex., modifier une donnée dans la source des données (le fichier brut) et cliquer sur un (voire deux) boutons pour mettre à jour l’article final ! On n’y est pas encore !!\nL’organisation de la rédaction est un gros chantier qui n’est pas du tout structuré en l’état."
  },
  {
    "objectID": "02_preparation.html#bonnes-pratiques-dans-le-système-de-récolte-des-données-qualtrics",
    "href": "02_preparation.html#bonnes-pratiques-dans-le-système-de-récolte-des-données-qualtrics",
    "title": "2  Préparation des données",
    "section": "2.1 Bonnes pratiques dans le système de récolte des données (Qualtrics, …)",
    "text": "2.1 Bonnes pratiques dans le système de récolte des données (Qualtrics, …)\nChaque participant·e reçoit un id partiellement anonymisé. Il est fourni par l’équipe de recherche (ce n’est pas construit par le ou la participant·e). L’id ne contient que des chiffres pour simplifier le problème des majuscules/minuscules à la saisie et éviter les confusions entre le zéro et la lettre o (oui oui, c’est du vécu). Ceci signifie que l’id dispose d’une structure qui permet de/d’ :\n\névaluer son authenticité\nfaciliter la catégorisation des données\nrepérer efficacement les id et leur catégorisation dans les traitement ultérieurs\n\n\nExemple : un id comme 12.47.694 est structuré comme suit groupe12.constantearbitraire47.nombrealéatoireà3chiffres.\n\nChaque id est vérifié dans Qualtrics, ce qui signifie qu’un·e participant·e doit confirmer l’id pour que le système passe à la suite. On relève aussi l’intérêt de demander à l’utilisateur·trice de confirmer son groupe d’appartenance en cochant un facteur dans une liste imposée dans Qualtrics. Ceci a l’avantage de repérer les saisies fantasques (une personne met un id bidon / un·e participant·e s’inscrit avec le bon id mais dans le mauvais groupe, …). Dans la préparation des données, il semble que l’on gagne ainsi un temps important pour trier les données valables. La confiance dans les données s’en trouve augmentée. On relève toutefois une faiblesse : le code n’est pas 100% anonyme et on peut toujours remonter à un groupe de participant·es. Il faut alors en amont s’engager à détruire le document qui a permis la génération des id.\nChaque questionnaire est identifié par 3 premières lettre significatives, le nombre d’items et un _:\n\nExemple : Questionnaire sur la motivation scolaire en 13 items est identifié par mot13.\n\nEnsuite, chacun des items est proprement nommé par ordre d’apparition, ce qui est fondamental, notamment pour le traitement des items inversés :\n\nExemple : mot13_1, mot13_2, …, mot13_13 (il semble que Qualtrics ajoute par défaut le underscore_ )"
  },
  {
    "objectID": "02_preparation.html#premières-étapes-dans-r-en-principe-les-noms-des-variables-sont-sains",
    "href": "02_preparation.html#premières-étapes-dans-r-en-principe-les-noms-des-variables-sont-sains",
    "title": "2  Préparation des données",
    "section": "2.2 Premières étapes dans R (en principe, les noms des variables sont sains)",
    "text": "2.2 Premières étapes dans R (en principe, les noms des variables sont sains)\nOn commence par le chargement des packages et l’importation du ou des fichiers de données. Dans cet exemple, on prend le cas (plus complexe) où nous devons gérer et associer deux data frames.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n# Importation des données Qualtrics à disposition ----\nd_t1_raw <- read_excel(\"crips2019_lv_raw_t1.xlsx\")\nd_t2_raw <- read_excel(\"crips2019_lv_raw_t2.xlsx\")\n\n\n2.2.1 ajout de la variable de temps dans chaque df (cas simple)\nChaque fichier représente un temps de mesure. Il nous suffit d’ajouter une variable indiquant cette information.\nDans cet exemple, on règle en même temps le problème des id qui contiennent éventuellement des majuscules.\n\n#Ajout de la variable temps sur chaque df et normalisation des id en minuscule.\n\nd_t1 <- d_t1_raw %>% \n  mutate(temps=\"temps 1\",\n         id=tolower(id)) \n\nd_t2 <- d_t2_raw %>% \n  mutate(temps=\"temps 2\",\n         id=tolower(id))\n\n\n\n2.2.2 catégorisation de la variable de temps (cas avec horodatage préalable)\nQuand on possède un unique fichier regroupant toutes les observations, on peut catégoriser les données à partir de l’horodateur.\n\n#modification de la variable \"RecordedDate\" en \"date\" en temps 1 et temps 2 tout en filtrant les id enregistrés hors temps 1 et temps 2.\n#mais on commence par la renommer.\n\nd <- d %>% \n  rename(date = RecordedDate) %>%  #dans cet ordre.\n  mutate(id = tolower(id)) #gestion de la casse.\n\nd <- d %>% \n  mutate(\n    date = case_when(date >= as.POSIXct(\"01.08.2019\", format=\"%d.%m.%Y\", tz=\"utc\") & date <= as.POSIXct(\"31.08.2019\", format=\"%d.%m.%Y\", tz=\"utc\") ~ \"temps 1\",\n                     date >= as.POSIXct(\"01.06.2020\", format=\"%d.%m.%Y\", tz=\"utc\") & date <= as.POSIXct(\"30.06.2020\", format=\"%d.%m.%Y\", tz=\"utc\") ~ \"temps 2\",\n                     TRUE ~ \"autre temps\")) #on privilégie case_when car on a 3 conditions et on va gérer les dates.\n\n#Au passage, R a modifié le type de variable \"date\". On le laisser respirer... et on filtre... (si j'intègre filter dans le pipe, ça bug...)\n\nd <- d %>% filter(date ==\"temps 1\" | date == \"temps 2\")\n\n\nOn est pas encore confiant sur la qualité du code ci-dessus.\n\n\n\n2.2.3 création d’un data frame unique\nA ce stade, à partir du cas simple, il ne semble pas y avoir de raison au maintien de 2 df différents. On peut créer un df unique à l’aide, simplement, de bind_rows. Cela nous évite de doubler les manipulations au temps 1 et au temps 2.\nAu préalable, on s’est assuré que les noms des variables correspondaient à notre nomenclature, et que l’ordre des questions dans chaque questionnaire était le même au temps 1 et au temps 2.\nLes éventuelles nouvelles variables du temps 2 sont bien traitées grâce à l’ajout de NA pour les observations du temps 1.\n\n#Mise en formation long sur un df\n\nd_long <- bind_rows(d_t1,d_t2)\n\n\nOn choisit la mise en format long (au lieu de wide) pour correspondre au attentes du traitement tidy des données. Cela signifie que chaque ligne est une observation et chaque colonne est une variable. Ceci implique que chaque participant·e se retrouve dans deux lignes : une concernant la modalité (facteur) temps 1 et l’autre selon la modalité temps 2. C’était déroutant au début mais on a adopté cette manière de faire.\n\n\n\n2.2.4 gestion des items à inverser\nLes items à inverser sont traités en étant strictement remplacés via la fonction mutate() dans le cadre de l’enregistrement d’un nouveau data frame. R permet de remonter les changements donc cet écrasement n’empêche pas la vérification des processus, étape par étape.\n\n#Recondage des variables au score inversé\n\nd_long <- d_long %>% \n  mutate(hbs20__7 = 6 - hbs20__7,\n         pec5__5 = 6 - pec5__5,\n         be8__4 = 8 - be8__4,\n         be8__5 = 8 - be8__5,\n         be8__8 = 8 - be8__8,\n         est10__3 = 5 - est10__3,\n         est10__5 = 5 - est10__5,\n         est10__7 = 5 - est10__7,\n         est10__10 = 5 - est10__10,\n         sou13__6 = 6 - sou13__6,\n         sou13__9 = 6 - sou13__9,\n         mot16__4 = 8 - mot16__4,\n         mot16__8 = 8 - mot16__8,\n         mot16__12 = 8 - mot16__12,\n         mot16__15 = 8 - mot16__15,\n         mot16__16 = 8 - mot16__16)\n\n\nLe code paraît fastidieux et potentiellement source d’erreurs. De plus, ce recodage s’accompagne d’une feuille annexe sur laquelle on a noté avec prudence les items en cause et la formule pour inverser les scores… On ne sait mieux faire…\n\nCe procédé d’écrasement facilite l’analyse de la cohérence interne ou le calcul des scores par la suite (cf. chapitre description).\n\n\n2.2.5 calcul du score de chaque questionnaire par observation\nLa variable qui contient le score global de chaque questionnaire par participant·e porte l’extension *_sco* :\n\nExemple : mot13_sco est la variable de score total de mot13_1 à mot13_13 avec les variables qui ont été inversées (sans conservation dans le df de l’item non-inversé).\n\n\n#Recondage des variables au score inversé\n\n#Création des moyennes de chaque questionnaire pour chaque observation\n\nd_long <- d_long %>% \n  mutate(hbs_sco = rowMeans(select(.,starts_with(\"hbs\")),na.rm =T),\n         pec_sco = rowMeans(select(.,starts_with(\"pec\")),na.rm =T),\n         be_sco  = rowMeans(select(.,starts_with(\"be\")) ,na.rm =T),\n         est_sco = rowMeans(select(.,starts_with(\"est\")),na.rm =T),\n         cli_sco = rowMeans(select(.,starts_with(\"cli\")),na.rm =T),\n         sou_sco = rowMeans(select(.,starts_with(\"sou\")),na.rm =T),\n         mot_sco = rowMeans(select(.,starts_with(\"hbs\")),na.rm =T))\n\n\nDe nouveau, on ne crée pas d’objet intermédiaire sachant que R sait très bien nous permettre de vérifier le processus, étape par étape.\n\nCe code paraît très efficace. Il se base sur notre nomenclature sans risque d’erreur, indépendamment du nombre de variable ou de la position des colonnes.\n\nOn apprécie, même si on ne comprend pas encore à satisfaction la fonction ´select´et son fonctionnement.\n\n\n\n2.2.6 filtrage des observations\nIci, on a essayé de développer une technique pour ne garder que les id qui se retrouvent strictement au temps 1 et au temps 2.\nLes enjeux sont cruciaux :\n\non doit s’assurer qu’un même id ne se retrouve pas plusieurs fois dans le même temps (un·e participant·e peut avoir rempli 2 fois le questionnaire du temps, p.ex.)\non doit aussi s’assurer que nous ferons nos comparaisons temps 1 / temps 2 sur des données complètes\n\nC’est notre présomption de base. Il est dès lors important de filtrer les observations de manière stricte.\nPour cela, nous avons :\n\ncréé un df de comparaison pour pouvoir dire à R quoi sélectionner. Ce df va, en deux étapes, ne garder que (1) les id uniques dans chaque temps puis (2) constituant une paire (t1, t2).\n\n\nd_comp <- d_long %>% \n  drop_na(id) %>% #par sécurité, on supprime les lignes dont l'id est vide\n  arrange(id) %>% #visuel uniquement\n  group_by(id, temps) %>% \n  count(id) %>% \n  filter(n==1) %>% #On s'est assuré que chaque id est unique dans chaque modalité de temps. On doit encore être sûrs qu'on a maintenant exactement une paire (t1,t2). Donc on continue le processus que R réalise dans cet ordre.\n  ungroup() %>% \n  group_by(id) %>% \n  count(id) %>% \n  filter(n==2) %>% #on ne garde que les paires de id qui se retrouvent dans t1 et t2. C'est notre grosse perte de données de ce traitement\n  ungroup()\n\n\nOn devrait vérifier la validité de cette méthode, sur le plan des bonnes pratiques stat, et aussi sur le plan du codage dans R…et aussi s’assurer qu’elle fonctionne bien comme on le pense en la mettant à l’épreuve.\n\n\ncréé un nouveau df qui ne contient plus que les paires souhaitées\n\n\n#Notre df de comparaison est prêt. On peut procéder à l'élagage de d_long.\n\nd_long_paired <- d_long %>% \n  filter(id %in% d_comp$id) %>% \n  mutate(group=ifelse(group==\"con\", \"contrôle\",\"expérimental\"))\n\n\nOn a été un peu sauvé avec le logique %in% mais sans bien savoir pourquoi == ne convient pas. Dans l’example, on en a profité pour modifier les facteurs de la variable group. Les forums ne sont pas clairs sur la différence entre ifelseet if_elseou encore case_when. On doit clarifier cela.\n\n\n\n2.2.7 gestion des données manquantes\n\npas encore de bonnes pratiques.\n\n\n\n2.2.8 gestion des données extrêmes\n\npas encore de bonnes pratiques."
  },
  {
    "objectID": "03_description.html#obtenir-une-synthèse-de-données",
    "href": "03_description.html#obtenir-une-synthèse-de-données",
    "title": "3  Description des données",
    "section": "3.1 Obtenir une synthèse de données",
    "text": "3.1 Obtenir une synthèse de données\nVoici deux exemples pour obtenir des petits résumés.\n\nd_long_paired_sum <- d_long_paired %>% \n   mutate(sex=ifelse(sex==\"1\", \"garçons\",\"filles\")) %>% \n   group_by(temps, group, sex) %>% \n  summarise(n=n())\n\nd_long_paired_sum2 <- d_long_paired %>% \n  group_by(temps, group) %>% \n  summarise(n=n(),\n            mean_hbs=mean(hbs_sco),\n            mean_pec=mean(pec_sco),\n            mean_be=mean(be_sco),\n            mean_est=mean(est_sco),\n            mean_cli=mean(cli_sco),\n            mean_sou=mean(sou_sco),\n            mean_mot=mean(mot_sco),\n            mean_sho1=mean(sho_1),\n            mean_sho2=mean(sho_2),\n            mean_sho3=mean(sho_3),\n            mean_sho4=mean(sho_4))"
  },
  {
    "objectID": "03_description.html#principes",
    "href": "03_description.html#principes",
    "title": "3  Description des données",
    "section": "3.2 Principes",
    "text": "3.2 Principes"
  },
  {
    "objectID": "03_description.html#procédures",
    "href": "03_description.html#procédures",
    "title": "3  Description des données",
    "section": "3.3 Procédures",
    "text": "3.3 Procédures"
  },
  {
    "objectID": "03_description.html#le-cas-des-boucles",
    "href": "03_description.html#le-cas-des-boucles",
    "title": "3  Description des données",
    "section": "3.4 Le cas des boucles",
    "text": "3.4 Le cas des boucles\nLa fonction for semble très utile pour faire faire des boucles. Quand je dois réaliser 10 plots de 10 VI, je peux juste préparer mon plot et l’intégrer dans une boucle. La contrainte semble être liée à aes et peut-être aussi au titre du plot dont on aimerait aussi “automatiser” la génération.\nInfos à comprendre et tester ici : https://statistique-et-logiciel-r.com/comment-utiliser-ggplot-dans-une-boucle-ou-dans-une-fonction/\nintégrer et expliquer le cas d’école réussi avec les données IBE:\n\n#######################\n#visualisation en loop#\n#######################\n# Liste des noms des variables que l'on veut (a à p uniquement).\nvar_list = names(d_paired)[6:21]\n\n# création de la liste pour accueillir les 16 (21-5) plots\nplot_list = list()\n\nfor (i in 1:16) {\n  p <- d_paired %>% \n    ggplot() +\n    aes(x = dat) +\n    aes_string(y = var_list[i]) +\n    geom_jitter(size = 5, alpha = .5, width = 0.3) +\n    stat_summary(fun = mean, geom = \"point\", size = 3, shape = 4, color = \"red\") +\n    stat_summary(fun = mean, geom = \"line\", aes(group = 1), color = \"red\") +\n    labs(title = paste(\"Mesure item\",i), y = \"Score\") +\n    theme(plot.title = element_text(hjust = 0.5))  \n  plot_list[[i]] = p\n}\ndev.off()\n\n# enregistrement des plots en png par fichier séparé avec un nom correspondant au nom de la variable et non de son numéro.\nfor (i in 1:16) {\n  temp_plot = plot_list[[i]]\n  ggsave(temp_plot, file=paste0(\"plot_\", var_list[[i]],\".png\"), width = 14, height = 10, units = \"cm\")\n}"
  },
  {
    "objectID": "03_description.html#tableaux",
    "href": "03_description.html#tableaux",
    "title": "3  Description des données",
    "section": "3.5 Tableaux",
    "text": "3.5 Tableaux"
  },
  {
    "objectID": "03_description.html#plots",
    "href": "03_description.html#plots",
    "title": "3  Description des données",
    "section": "3.6 Plots",
    "text": "3.6 Plots\nintégrer mes trouvailles de crips2019 et ce qu’un plot doit montrer.\nTravail avec Zoe. Notes à intégrer :\nRéaliser des boxplots avec barres d’erreurs\n[ ] –> plutôt utiliser select des variables ou filter des participants gather –> 1er argument nom et 2ème argument valeur\nset.sid dans Rmarkdown pour figer les aléatoires, p.ex. le jitter pour pas que ça change à chaque lancement.\ninstaller des kits de couleurs au besoin.\nshape : les numéros correspondent à des formes de points.\ngeom_line : 3 arguments minimum. avec group. –> pourquoi “group” et pourquoi “1”. Alt + N = ~\njitter –> position et positionjitterdodge pour comparer G et F\nAfficher toutes les catégries, même les vides :\n\n    scale_x_discrete(drop = FALSE) # Forcer l'affichage des catégories vides\n# A voir si la variable doit être un facteur\nd <- d %>% \n  mutate(\n         q1 = factor(q1, levels = c(\"1\",\"2\",\"3\",\"4\"), labels = c(\"pas du tout\", \"plutôt non\", \"plutôt oui\", \"tout à fait\")),\n         q2 = factor(q2, levels = c(\"1\",\"2\",\"3\",\"4\"), labels = c(\"pas du tout\", \"plutôt non\", \"plutôt oui\", \"tout à fait\")),\n         q3 = factor(q3, levels = c(\"1\",\"2\",\"3\",\"4\"), labels = c(\"pas du tout\", \"plutôt non\", \"plutôt oui\", \"tout à fait\")),\n         q4 = factor(q4, levels = c(\"1\",\"2\",\"3\",\"4\"), labels = c(\"pas du tout\", \"plutôt non\", \"plutôt oui\", \"tout à fait\")),\n  )"
  },
  {
    "objectID": "04_rapport.html#principes",
    "href": "04_rapport.html#principes",
    "title": "4  Rapport",
    "section": "4.1 Principes",
    "text": "4.1 Principes\nAvec ressources (fameux document PDF de CS durant le pre-doc) Ce qui est attendu dans un document de type rapport. (à l’aide du rapport de ZL et de celui en production pour LV)\nKable et KableExtra\nbon affichage d’un tableau\ninsérer image externe"
  },
  {
    "objectID": "04_rapport.html#procédures-clés",
    "href": "04_rapport.html#procédures-clés",
    "title": "4  Rapport",
    "section": "4.2 Procédures clés",
    "text": "4.2 Procédures clés"
  },
  {
    "objectID": "04_rapport.html#un-mot-sur-les-normes-apa",
    "href": "04_rapport.html#un-mot-sur-les-normes-apa",
    "title": "4  Rapport",
    "section": "4.3 Un mot sur les normes APA",
    "text": "4.3 Un mot sur les normes APA"
  },
  {
    "objectID": "04_rapport.html#un-mot-sur-bookdown-et-github",
    "href": "04_rapport.html#un-mot-sur-bookdown-et-github",
    "title": "4  Rapport",
    "section": "4.4 Un mot sur Bookdown et GitHub",
    "text": "4.4 Un mot sur Bookdown et GitHub\ncf. chapitre 1."
  },
  {
    "objectID": "05_etudes_de_cas.html#data-masking-walrus-opérator-et-sting-interpolation",
    "href": "05_etudes_de_cas.html#data-masking-walrus-opérator-et-sting-interpolation",
    "title": "5  Etudes de cas",
    "section": "5.1 Data masking, Walrus opérator et sting interpolation",
    "text": "5.1 Data masking, Walrus opérator et sting interpolation\nExemple de Mutate dans une fonction ou même au sein d’un loop. voir sandbox.\n\n# avec tunnel. pas essayé encore.\nfun <- function(df, var) {\n  df <- df %>% \n    mutate(\"{var}\" := key - {{var}})\n}\n# avec pull(). OK.\n\nfun <- function(df, var) {\n  df <- df %>% \n    mutate(\"{var}\" := key - pull(.,var))\n}"
  }
]